{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "KduhWya0I0Vl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79Hz6Au9ebpv",
        "outputId": "1730b448-cd26-4212-a044-1acf2a9c6ab5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "train_file_path = '/content/drive/MyDrive/Colab Notebooks/train.csv'\n",
        "test_file_path = '/content/drive/MyDrive/Colab Notebooks/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_file_path)\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyeDdpkPNIm6",
        "outputId": "cdae96bd-acbc-46b7-b1d0-55054ad58e85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
            "0   914403  B0009W5KHM   AV6QDP8Q0ONK4                     2   \n",
            "1   354887  6303079709  A2I8RXJN80A2D2                     0   \n",
            "2  1407653  B004H0M2XC  A3FHV3RV8Z12E6                     0   \n",
            "3  1377458  B003ZJ9536  A12VLTA3ZHVPUY                     1   \n",
            "4   475323  630574453X  A13NM1PES9OXVN                     2   \n",
            "\n",
            "   HelpfulnessDenominator        Time  \\\n",
            "0                       2  1341014400   \n",
            "1                       0  1168819200   \n",
            "2                       0  1386201600   \n",
            "3                       1  1348704000   \n",
            "4                       3   970012800   \n",
            "\n",
            "                                         Summary  \\\n",
            "0                                  GOOD FUN FILM   \n",
            "1                                   Movie Review   \n",
            "2             When is it a good time to Consent?   \n",
            "3                                          TRUTH   \n",
            "4  Intelligent and bittersweet -- stays with you   \n",
            "\n",
            "                                                Text  Score  \n",
            "0  While most straight to DVD films are not worth...    5.0  \n",
            "1  I have wanted this one for sometime, also.  I ...    5.0  \n",
            "2  Actually this was a pretty darn good indie fil...    4.0  \n",
            "3  Episodes 37 to 72 of the series press on in a ...    5.0  \n",
            "4  I was really impressed with this movie, but wa...    3.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.merge(\n",
        "    train_df[['Id', 'ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary', 'Text']],\n",
        "    on='Id',\n",
        "    how='left'\n",
        "    )\n",
        "\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aB-V5vkQANO",
        "outputId": "cb69d062-8884-4239-9119-7e3099ee2ac0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Id  Score   ProductId          UserId  HelpfulnessNumerator  \\\n",
            "0  1323432    NaN  B0034G4P30  A120UTHQDQIJGH                     0   \n",
            "1  1137299    NaN  B0012IWO0I  A3SJBFCTJWBFT2                     1   \n",
            "2  1459366    NaN  B005FUTBSC  A1V6FRU7EXP6N9                     0   \n",
            "3   931601    NaN  B000AREXBU   ARXDDR76Z5Q2I                     5   \n",
            "4  1311995    NaN  B002ZG99B8   A2XAS9GVZL3B1                     2   \n",
            "\n",
            "   HelpfulnessDenominator        Time  \\\n",
            "0                       0  1391040000   \n",
            "1                       1  1388188800   \n",
            "2                       0  1356739200   \n",
            "3                       5  1169510400   \n",
            "4                       2  1392595200   \n",
            "\n",
            "                                             Summary  \\\n",
            "0                                  Okay for a rental   \n",
            "1                                     Great for kids   \n",
            "2                                         good movie   \n",
            "3  Excellent quality dvd.  Don't pay big bucks fo...   \n",
            "4                                     A mixed review   \n",
            "\n",
            "                                                Text  \n",
            "0  This movie was just alright for me. I think pe...  \n",
            "1  My kids love this movie.  Exciting and fun to ...  \n",
            "2  The effects were good, not the best but far fr...  \n",
            "3  I just got a copy of this S. Korean dvd of \"He...  \n",
            "4  OK, to put this clearly and bluntly... if you ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_helpfulness_ratio(df):\n",
        "    if 'HelpfulnessRatio' not in df.columns:\n",
        "        def calculate_helpfulness_ratio(row):\n",
        "            return row['HelpfulnessNumerator'] / row['HelpfulnessDenominator'] if row['HelpfulnessDenominator'] != 0 else 0\n",
        "        df['HelpfulnessRatio'] = df.apply(calculate_helpfulness_ratio, axis=1)\n",
        "    return df\n",
        "\n",
        "def add_date_features(df):\n",
        "    if 'Year' not in df.columns or 'Month' not in df.columns or 'Day' not in df.columns:\n",
        "        df['Year'] = pd.to_datetime(df['Time'], unit='s').dt.year\n",
        "        df['Month'] = pd.to_datetime(df['Time'], unit='s').dt.month\n",
        "        df['Day'] = pd.to_datetime(df['Time'], unit='s').dt.day\n",
        "    return df\n",
        "\n",
        "def add_tfidf_features(train_df, test_df, n_tfidf_features=100, n_svd_components=30):\n",
        "    if not any(col.startswith('TFIDF_') for col in train_df.columns):\n",
        "        tfidf_vectorizer = TfidfVectorizer(max_features=n_tfidf_features, stop_words='english')\n",
        "        train_text_combined = train_df['Summary'].fillna('') + \" \" + train_df['Text'].fillna('')\n",
        "        tfidf_train = tfidf_vectorizer.fit_transform(train_text_combined)\n",
        "\n",
        "        svd = TruncatedSVD(n_components=n_svd_components, random_state=42)\n",
        "        tfidf_train_reduced = svd.fit_transform(tfidf_train)\n",
        "        tfidf_train_df = pd.DataFrame(tfidf_train_reduced, columns=[f'TFIDF_SVD_{i}' for i in range(n_svd_components)])\n",
        "        train_df = pd.concat([train_df.reset_index(drop=True), tfidf_train_df], axis=1)\n",
        "\n",
        "        # Transform test data with the same vectorizer and SVD\n",
        "        test_text_combined = test_df['Summary'].fillna('') + \" \" + test_df['Text'].fillna('')\n",
        "        tfidf_test = tfidf_vectorizer.transform(test_text_combined)\n",
        "        tfidf_test_reduced = svd.transform(tfidf_test)\n",
        "        tfidf_test_df = pd.DataFrame(tfidf_test_reduced, columns=[f'TFIDF_SVD_{i}' for i in range(n_svd_components)])\n",
        "        test_df = pd.concat([test_df.reset_index(drop=True), tfidf_test_df], axis=1)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Apply features to training and testing sets\n",
        "train_df = add_helpfulness_ratio(train_df)\n",
        "train_df = add_date_features(train_df)\n",
        "test_df = add_helpfulness_ratio(test_df)\n",
        "test_df = add_date_features(test_df)\n",
        "\n",
        "# Add TF-IDF features with dimensionality reduction using TruncatedSVD\n",
        "train_df, test_df = add_tfidf_features(train_df, test_df, n_tfidf_features=50, n_svd_components=20)"
      ],
      "metadata": {
        "id": "8DAZh4sM97-B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where Score is null in train_df\n",
        "train_df = train_df.dropna(subset=['Score'])\n",
        "\n",
        "# Prepare the training set\n",
        "X_train = train_df.drop(columns=['Id', 'ProductId', 'UserId', 'Score', 'Summary', 'Text'], errors='ignore')\n",
        "y_train = train_df['Score']  # Use actual Score values as the target variable\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "X_train_set, X_val_set, y_train_set, y_val = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    test_size=0.25,\n",
        "    random_state=0\n",
        ")"
      ],
      "metadata": {
        "id": "3eFEENxii0Pz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the RandomForest model\n",
        "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_model.fit(X_train_set, y_train_set)\n",
        "\n",
        "# Predict on validation set using RandomForest\n",
        "y_pred_rf = rf_model.predict(X_val_set)\n",
        "accuracy_rf = (y_pred_rf == y_val).mean()\n",
        "\n",
        "# Store RandomForest evaluation metrics\n",
        "evaluation_results_rf = {\n",
        "    \"Model\": \"RandomForest Classifier\",\n",
        "    \"Accuracy\": accuracy_rf\n",
        "}\n",
        "print(\"RandomForest Validation Accuracy:\", accuracy_rf)"
      ],
      "metadata": {
        "id": "cvtoL9uYJuye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4433e412-14cd-40f4-afbc-5b05c3eb8663"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Validation Accuracy: 0.5487698472542387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test data for prediction, excluding non-feature columns\n",
        "X_test = test_df.drop(columns=['Id', 'ProductId', 'UserId', 'Summary', 'Text', 'Score'], errors='ignore')\n",
        "\n",
        "# Predict the Score on the test set and store results in test_df\n",
        "test_df['Score'] = rf_model.predict(X_test)\n",
        "\n",
        "# Prepare the submission file with only Id and Score columns\n",
        "submission = test_df[['Id', 'Score']]\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "submission.head()"
      ],
      "metadata": {
        "id": "WBAF8qwmJ74X"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "id": "2Zgc7tmv7k22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "812f937d-20ec-46e9-dde7-09de617e26e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05220f53-f655-4e6c-b854-cdecc06b4e03\", \"submission.csv\", 1983144)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}